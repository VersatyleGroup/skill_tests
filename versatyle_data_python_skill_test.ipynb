{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-yKUrxnoniR"
      },
      "source": [
        "Versatyle Python Skill Test - *Take-Home Assignment*\n",
        "---------------------------------------------------\n",
        "\n",
        "In this assignment, you will go through several questions that together constitute a workflow of basic data operations in Python where each question builds upon the next.\n",
        "\n",
        "First, upload this notebook in [Google Colab](https://colab.research.google.com/).\n",
        "Make sure you download and store the Excel file *data.xlsx* locally and upload it. The code to do this is already in place below. The data consists of master data on passengers who were onboard the Titanic, and it is enriched with extra (fictional) information on each passenger.\n",
        "\n",
        "You will start by performing SQL-like operations (using pandas) on 3 datasets. The resulting dataframe will then be used to implement cleaning rules on the data. Finally you can use the cleaned dataset to build a SQL query as string which you will output.\n",
        "\n",
        "**Use Google Chrome to avoid possible issues with google colab.**\n",
        "\n",
        "There is no real time limit, but we don't want to take too much of your time. We think this test should be manageable in approximately one or two hours. The quality, readability, and efficiency of the code are most important. \n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bb40P6mq39P"
      },
      "outputs": [],
      "source": [
        "# RUN THIS CELL FIRST, TO UPLOAD THE DATA\n",
        "from google.colab import files\n",
        "data = files.upload()\n",
        "\n",
        "# Upload the `data.xlsx` file below..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF4A9rt9YOMP"
      },
      "source": [
        "Make sure the name of the file you uploaded is the same as the one below read by the `pd.read_excel()` function. If you don't make any changes everything will run correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQrBrlW6tHKG"
      },
      "outputs": [],
      "source": [
        "# NOW RUN THIS CELL, TO READ THE DATA\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "all_data_sets = pd.read_excel(io.BytesIO(data['data.xlsx']), sheet_name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcXSInT7YEWr"
      },
      "source": [
        "You now should have 3 separate dataframes stored in `all_data_sets`. Do some checks to see if that is the case. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmZkLMfhZYbQ"
      },
      "source": [
        "## Exercise 1\n",
        "---------------------\n",
        "\n",
        "The three datasets need to be joined so that we will end up with one dataframe on which the cleaning requirements are performed. \n",
        "\n",
        "#### **a)**\n",
        "Create a new dataframe (e.g. `passenger_extended_df`) that extends the **passengers** table (second dataset/tab in the xlsx) with **extra** information (third dataset/tab in the xlsx). Investigate the data to find the join attribute(s).\n",
        "Make sure that the resulting table contains all rows from **passengers** dataset. Then remove  passengers that have a `nan` value for the `age` attribute. \n",
        "\n",
        "#### **b)**\n",
        "Obtain the final dataframe by joining the **titanic** table with the dataframe created in **a)**. Again, analyze the data to find the proper join attribute(s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g71dHxNfZtlo"
      },
      "outputs": [],
      "source": [
        "### Code for question 1a ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6hDJ3mvdGew"
      },
      "outputs": [],
      "source": [
        "### Code for question 1b ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcUCfx2NdO-G"
      },
      "source": [
        "# Exercise 2\n",
        "------------------------------------------\n",
        "Now that we have our data in one set we would like to do some cleaning. \n",
        "\n",
        "\n",
        "#### **a)**\n",
        "We need a new column called `RequirementX` based on whether someone survived or not and on the `Embarked` value. Fill the column according to the following rules:\n",
        " - If a passenger survived and `Embarked` equals `NaN` or \"S\", the cell has to take the value \"...\" (string with three dots)\n",
        " - If a passenger survived and `Embarked` equals \"C\" or \"Q\", the cell has to take the value \"00A\"\n",
        " - If a passenger did not survive and `Embarked` equals \"Q\", the cell has to take the value \"Passed with Q\"\n",
        " - Else, the cell has to take the value \"TBD\"\n",
        "\n",
        "\n",
        "#### **b)** \n",
        "For all rows, delete all non-digit (1-9) characters in the \"Ticket\" column.\n",
        "\n",
        "\n",
        "#### **c)**\n",
        "If a passenger is born before 1965 clear out their `Email`.\n",
        "\n",
        "\n",
        "#### **d)** \n",
        "Print the number of passengers that use *yahoo.com* as their `Email` provider.\n",
        " \n",
        "\n",
        "#### **e)** \n",
        "Select 30 passengers, 15 that have completed High School and 15 that have done a Bachelor and keep only the columns `Sex`, `PassengerId`, `Education` and `Company`.\n",
        "Rename the columns according to the following mapping: \n",
        "* `Sex` --> `st`\n",
        "* `PassengerId` --> `sa`\n",
        "* `Education` --> `tt`\n",
        "* `Company` --> `ta`\n",
        "\n",
        "Give the output a new name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwxN8crGlkIs"
      },
      "outputs": [],
      "source": [
        "### Code for question 2a ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suOMcRadltZ-"
      },
      "outputs": [],
      "source": [
        "### Code for question 2b ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gvjw4UyltuX"
      },
      "outputs": [],
      "source": [
        "### Code for question 2c ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBJAgO0UluLd"
      },
      "outputs": [],
      "source": [
        "### Code for question 2d ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nQ-XLTLlupa"
      },
      "outputs": [],
      "source": [
        "### Code for question 2e ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcPw2uwql1aV"
      },
      "source": [
        "# Exercise 3  \n",
        "----------------------------------------\n",
        "\n",
        "Using the more compact table from our previous task **2e)** we want to create two SQL queries as strings, then output them to the screen. You are not expected to work with SQL or execute the queries.\n",
        "\n",
        "Consider the following example dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JODhS8e9msrx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  st           sa      tt  ta\n",
            "0  A          001  table1  xa\n",
            "1  B          007  table1  xb\n",
            "2  A        40021  table1  xc\n",
            "3  Z        90833  table2  ya\n",
            "4  Z  hello World  table2  yb\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "example_data: dict = {\n",
        "    'st': ['A', 'B', 'A', 'Z', 'Z'], \n",
        "    'sa': ['001', '007', '40021', '90833', 'hello World'], \n",
        "    'tt': ['table1', 'table1', 'table1', 'table2', 'table2'],\n",
        "    'ta': ['xa', 'xb', 'xc', 'ya', 'yb']\n",
        "}\n",
        "example_df = pd.DataFrame.from_dict(example_data)\n",
        "\n",
        "print(example_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s3WjBrSndWo"
      },
      "source": [
        "For each group in the `tt` column, we would like to have a separate string. Since the dataframe from the previous exercise will have two distinct `tt` values by design, your code should output two strings. \n",
        "\n",
        "Based on the example dataframe, try to find a pattern for structuring and creating the SQL query.\n",
        "Note the use of backticks. If values are added to the `tt` column, your program should output more strings.\n",
        "\n",
        "Using the example data, your program should **exactly** create and print the following string for **table1**:\n",
        "```sql\n",
        "SELECT A.`001` as `xa`, B.`007` as `xb`, A.`40021` as `xc` \n",
        "FROM schema.A + schema.B\n",
        "```\n",
        "\n",
        "And this for **table2**: \n",
        "```sql\n",
        "SELECT Z.`90833` as `ya`, Z.`hello World` as `yb`\n",
        "FROM schema.Z\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpHQHSlLo6tZ"
      },
      "outputs": [],
      "source": [
        "### Code for question 3 ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise 4\n",
        "----------------------------------------\n",
        "Have your code reviewed and optimized by your favorite AI. Evaluate the AI's suggestions and explain whether the code actually improves or not, you do not have to change the code we are interessed in your evaluation of the AI's output. \n",
        "\n",
        "Please tell us the AI you used and in what manner."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Zenit_AssignmentDataEngineer_v3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
