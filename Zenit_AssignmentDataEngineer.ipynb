{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zenit_AssignmentDataEngineer_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-yKUrxnoniR"
      },
      "source": [
        "Data Engineer / Data Science position at Zenit - *Take Home Assignment*\n",
        "---------------------------------------------------\n",
        "\n",
        "In this assignment you will go through several questions that together constitute a workflow of some basic data operations in Python. \n",
        "Each question builds up on the next.\n",
        "\n",
        "First make sure you download and store the excel file *data.xlsx* locally and upload it here. The code to do this with is already in place below. The data consists of some master data on passengers that were onboard the Titanic and it is enriched with some extra (fictional) information on each passenger. The data does not always make sense, that is not a problem.\n",
        "\n",
        "You will start with performing some SQL-like operations (but using pandas) on 3 datasets. The resulting dataframe will then be used to implement some cleaning rules on the data. Hereafter you can use the cleaned dataset to build up a SQL query which you will have to output.\n",
        "\n",
        "**Please use Google Chrome.**\n",
        "\n",
        "\n",
        "There is no real time limit, but it should be manageable in approximately one hour. The quality and efficiency of the code is most important. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bb40P6mq39P"
      },
      "source": [
        "# RUN THIS CELL FIRST\n",
        "from google.colab import files\n",
        "data = files.upload()\n",
        "\n",
        "# Upload the `data.xlsx` file below..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF4A9rt9YOMP"
      },
      "source": [
        "Make sure the name of the file you uploaded is the same as the one below read by the `pd.read_excel()` function. If you don't make any changes everything will run correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQrBrlW6tHKG"
      },
      "source": [
        "# NOW RUN THIS CELL\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "all_data_sets = pd.read_excel(io.BytesIO(data['data.xlsx']), sheet_name=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcXSInT7YEWr"
      },
      "source": [
        "You now should have 3 seperate dataframes stored in `all_data_sets`. Do some checks to see if that is the case. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmZkLMfhZYbQ"
      },
      "source": [
        "## Excercise 1\n",
        "---------------------\n",
        "\n",
        "The three datasets need to be joined so that we will end up with one dataframe on which the cleaning requirements are performed. \n",
        "\n",
        "#### **a)**\n",
        "Create a new dataframe (e.g. `passenger_extended_df`) that extends the **passengers** table (second dataset in `all_data_sets`) with **extra** information (third dataset in `all_data_sets`). Investigate the data to find the join attribute(s).\n",
        "Make sure that the resulting table contains all rows from\n",
        "`passengers` dataset. Then remove those passengers that have a `nan` value for the `age` attribute age. \n",
        "\n",
        "#### **b)**\n",
        "Obtain the the final dataframe by joining the **titanic** table with the dataframe created in **a)**. Again, analyse the data to find the proper join attribute(s).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g71dHxNfZtlo"
      },
      "source": [
        "### Code for question 1a ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6hDJ3mvdGew"
      },
      "source": [
        "### Code for question 1b ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcUCfx2NdO-G"
      },
      "source": [
        "# Exercise 2\n",
        "------------------------------------------\n",
        "Now that we have our data in one table we would like to do some cleaning. \n",
        "\n",
        "#### **a)**\n",
        "We need a new column called `RequirementX` based on whether someone survived or not and on the `Embarked` value. Fill the column according to the following rule:\n",
        " - If a passenger survived and `Embarked` equals \"NaN\" or \"S\", the cell has to take the value *\"...\"* (three dots)\n",
        " - If a passenger survived and `Embarked` equals \"C\" or \"Q\", the cell has to take the value \"*00A*\"\n",
        " - If a passenger did not survive and `Embarked` equals \"Q\", the cell has to take the value  \"*Passed with Q*\"\n",
        " - Else, the cell has to take the value \"*TBD*\"\n",
        "\n",
        "\n",
        "#### **b)** \n",
        "For all rows, delte all non-digit (1-9) characters in the \"Ticket\" column.\n",
        "\n",
        "#### **c)**\n",
        "If a passenger is born before 1965 clear out their `Email`.\n",
        "\n",
        "#### **d)** \n",
        "Print the number of passengers that use *yahoo.com* as their `Email` provider.\n",
        " \n",
        "\n",
        "#### **e)** \n",
        "Select 30 passengers, 15 that have completed High School and 15 that have done a Bachelor and keep only the columns `Sex`, `PassengerId`, `Education` and `Company`.\n",
        "Rename the columns according to the following mapping: \n",
        "* `Sex` --> `st`\n",
        "* `PassengerId` --> `sa`\n",
        "* `Education` --> `tt`\n",
        "* `Company` --> `ta`\n",
        "\n",
        "Give this table a new name "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxN8crGlkIs"
      },
      "source": [
        "### Code for question 2a ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suOMcRadltZ-"
      },
      "source": [
        "### Code for question 2b ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gvjw4UyltuX"
      },
      "source": [
        "### Code for question 2c ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBJAgO0UluLd"
      },
      "source": [
        "### Code for question 2d ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nQ-XLTLlupa"
      },
      "source": [
        "### Code for question 2e ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcPw2uwql1aV"
      },
      "source": [
        "# Excercise 3 \n",
        "----------------------------------------\n",
        "\n",
        "Using the more compact table from **2e)** we will structure a SQL like strings which your program should print to the screen. For each group in the `tt` column, we would like to have a seperate string. You are not expected to work with sql or provide real queries. Based on the dataframe, try to find a pattern for structuring the string.\n",
        "\n",
        "Consider the following test dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JODhS8e9msrx"
      },
      "source": [
        "import pandas as pd\n",
        "test_df_dic = {\n",
        "    'st': ['A', 'B', 'A', 'Z', 'Z'], \n",
        "    'sa': ['001', '007', '40021', '90833', 'hello World'], \n",
        "    'tt': ['table1', 'table1', 'table1', 'table2', 'table2'],\n",
        "    'ta': ['xa', 'xb', 'xc', 'ya', 'yb']\n",
        "}\n",
        "test_df = pd.DataFrame.from_dict(test_df_dic)\n",
        "test_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s3WjBrSndWo"
      },
      "source": [
        "Your program should then output **exactly** this for **table1**:\n",
        "```\n",
        "SELECT A.`001` as `xa`, B.`007` as `xb`, A.`40021` as `xc` \n",
        "FROM schema.A + schema.B\n",
        "```\n",
        "And this for **table2**: \n",
        "```\n",
        "SELECT Z.`90833` as `ya`, Z.`hello World` as `yb`\n",
        "FROM schema.Z\n",
        "```\n",
        "\n",
        "Since your dataframe will have two distinct `tt` values by design, your code should output two strings. Note the use of backticks, and the fact that if there are multiple source tables you can just add them. In real life we would of course perform a join on some field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpHQHSlLo6tZ"
      },
      "source": [
        "### Code for question 3 ###"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}